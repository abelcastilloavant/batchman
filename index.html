<!DOCTYPE html>
<html lang="en" class="">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="description" content="Batchman is a wrapper for R methods to run them in arbitary batches. Some methods crash when running on large inputs. Batchman helps prevent those crashes, and helps increase speed where batching is useful.">

    <title>A wrapper for R methods to run them in arbitrary batches.</title>

    <link rel="stylesheet" media="all" href="stylesheets/rocco.css" />
    <link rel="stylesheet" media="all" href="stylesheets/github-markdown.css" />

    <script src="assets/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>

    <style type="text/css">
      .header {
        position: fixed;
        top: 0px;
        width: 100%;
        background-color: rgba(0, 0, 0, 0.25);
        padding: 10px;
      }
      
      .header a {
        padding-right: 30px;
      }

      .container {
        margin-top: 40px;
      }

      body {
        padding: 0;
        margin: 0;
      }

      div.code-background {
        float: right;
        position: fixed;
        z-index: -1;
        height: 100%;
        background-color: #f8f8ff;
        width: 60%;
        right: 0px;
      }

      div.section {
        clear: both;
        margin: 0; padding: 0;
      }

      div.code {
        float: right;
        width: 60%;
      }

      code.R {
        font-size: 1.2em;
        line-height: 2em;
        margin-top: 0em;
        margin-bottom: -2em;
        padding-top: 0;
        margin-top: -1em;
      }

      code.R > span.spacer {
        position: relative;
      }

      div.code > pre {
        margin: 0;
        padding-left: 2em;
        margin-top: 0;
        margin-bottom: 0;
      }

      div.markdown {
        padding: 1em;
        padding-top: 0;
        background: #fff;
        float: left;
        width: 35%;
      }
    </style>

  </head>

  <body>
    <div class="header">
      <a href="https://github.com/robertzk/rocco">
        <img id="rocco-logo" src="https://img.shields.io/badge/Generated by rocco_v0.2.1.2-%E2%9C%93-blue.svg"/>
      </a>
    </div>
    <div class="container">

      <div class="code-background"></div>

        <div class="section">
          <div class="markdown markdown-body">
            <h1>batch.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p><code>batch</code> is where all the action happens.  <code>batch</code> is a functional &ndash; it takes a function as
an argument (among many other arguments) and returns a function.  The returned function is
a modified version of the original function that will process inputs in batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">
#' batch maps a function to a batched version of that function.
#'
#' @param batch_fn function. The method to batch over.</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We need to know what keys will be the ones that will be batched versus the ones that
are not to be batched.  For example, for <code>mean</code>, we would want to batch the vector of numbers
but we would not like to batch along the optional <code>na.rm</code> argument.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' @param keys vector. The names of the keys within the function to batch.
#'   Can be "..." if one is batching a splat function with no keys.</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>A splitting strategy is a methodology to split up the inputs.  Right now the default one
that comes with batchman seems to handle every scenario well enough, and I&#39;ve never come up
with a reason to roll a custom splitting_strategy.  But I leave it to you to decide!</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' @param splitting_strategy function. The strategy used to split up inputs.
#'   Leave NULL to use the versatile default splitting strategy.</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The combination strategy is about how to recombine the inputs once they are processed in
batch.  The default one will handle pretty much anything, but the trade-off is that doing so
is slow.  So it&#39;s a good idea to pass a more specific combination_strategy if you can.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' @param combination_strategy function. The strategy used to recombine batches.
#'   Defaults to class-agnostic combination.
#' @param size numeric. The size of the packets. Default 50.
#' @param trycatch logical. Whether to wrap the function in a tryCatch block.
#'   Can be used to store and retrieve partial progress on an error.
#' @param batchman.verbose logical. Whether or not to announce progress by printing dots.
#' @param stop logical. Whether trycatch should stop if an error is raised.
#' @param retry integer. The number of times to retry on error. 0 for no retrying.
#' @param sleep integer. Time in seconds to sleep between batches.
#' @param parallel logical. Use parallel::mclapply to execute your batches. Incompatible with retry.
#' @param ncores integer. Number of cores to use if parallel is set to true. Notice that it doesn't
#'   work on windows.
#' @return a batched version of the passed function.
#' @examples
#'   batched_identity <- batch(identity, "x", combination_strategy = c, size = 10)
#'   batched_identity(seq(100))
#'   # Does identity, but in batches of 10.
#' @export
batch <- function(
    batch_fn,
    keys,
    splitting_strategy = NULL,
    combination_strategy = batchman::combine,
    size = 50,
    trycatch = FALSE,
    batchman.verbose = isTRUE(interactive()),
    stop = FALSE,
    retry = 0,
    sleep = 0,
    ncores = parallel::detectCores(),
    parallel = FALSE
) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Parallellized code will behave oddly if some of the code stops for an error, so it&#39;s best not to do it.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    if(isTRUE(parallel) && isTRUE(trycatch)) {
      stop('Please choose speed or robustness. (parallel or retry. cannot have both)')
    }
    if (is.batched_fn(batch_fn)) return(batch_fn)
    if (missing(keys)) stop("Keys must be defined.")
    if (isTRUE(stop) || retry > 0) trycatch <- TRUE
    if (!is.numeric(retry) || retry %% 1 != 0 || retry < 0) {
      stop("Retry must be an positive integer.")
    }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Batchman can store partial progress on runs if it stops unexpectedly.
We should clear it on another run where partial progress is desired.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    if (isTRUE(trycatch)) partial_progress$clear()
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The goal is to swap the function with a batched version of itself.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    batched_fn <- function(...) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>So we create a batched function.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      batched_fn <- make_batched_fn(decide_strategy(splitting_strategy))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>And then call it with the arguments that would have been passed
to the non-batched function.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      batched_fn(...)
    }
    attr(batched_fn, "batched") <- TRUE
    class(batched_fn) <- c("batched_function", "function")

</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The rest are just the helper functions.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    make_batched_fn <- function(splitting_strategy) {
      function(...) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The splitting strategy is how inputs are borken up into batches.
Each call of the splitting strategy will return the next batch.
So the first time it is called you get the first batch, the second
time it is called you get the second batch, until you get a
marker that there are no batches remaining.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        next_batch <- splitting_strategy(...)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Once we have the next batch, we process all the batches.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        process_batches(next_batch)
      }
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The splitting strategy will either be the default strategy or the
custom strategy passed by the user.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    decide_strategy <- function(splitting_strategy) {
      if (is.null(splitting_strategy)) { default_strategy }
      else { splitting_strategy }
    }


    default_strategy <- function(...) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We use <code>match.call</code> to extract all the arguments that are being passed to
the function we want to batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      args <- match.call(call = substitute(batch_fn(...)), definition = batch_fn)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We then look at the keys the user passed in saying they want to batch
and the args that the function actually uses, and check that the keys
are in the args.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      keys <- match_keys_with_args(args, keys)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Sometimes the args being passed are function calls. If so, they will be
evaluated during every batch, which is time intensive. To avoid this,
we pre-evaluate them in advance, keeping the results in an in-memory cache.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      args <- cache_args_that_are_functions(args, keys)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We now want to know the positions of the keys within the list of args.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      where_the_keys_at <- find_keys_within_args(args, keys)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If there aren&#39;t any keys, return NULL</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      if (length(where_the_keys_at) == 0) return(NULL)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Use the indicies to find the first key to evaluate</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      key_to_eval <- args[[where_the_keys_at[[1]]]]</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If the key is NULL, return NULL</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      if (is.null(key_to_eval)) return(NULL)

      run_length <- calculate_run_length(key_to_eval)
      if (run_length > size && verbose_set()) {
        cat("More than", size, "inputs detected.  Batching...\n")
      }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Each call of the batch_calls function will return the next batch until
there are no batches left.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      batch_calls(run_length, where_the_keys_at, args, size)
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Find the keys within the args and error if no keys are found.
keys are the arguments we are batching over.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    match_keys_with_args <- function(args, keys) {
      if (!identical(keys, "...")) keys <- keys[keys %in% names(args)]
      if (length(keys) == 0) stop("Bad keys - no batched key matches keys passed.")
      keys
    }

    cache_args_that_are_functions <- function(args, keys) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If any key is a call (a function), call it once now ahead of time, so
that it is not evaluated in every batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      for (key in keys) {
        if (is.call(args[[key]]))
          args[[key]] <- eval(args[[key]], envir = parent.frame(environment_that_contains_the_key(key)+1))
      }
      args
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Return the index positions of the keys within the arguments.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    find_keys_within_args <- function(args, keys) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If we are batching a splat, that means we want to batch by every argument, so
we return every valid position.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      if(identical(keys, "...")) seq(2, length(args))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Otherwise, we use a grep to find the keys within the args.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      else grep(paste0(keys, collapse="|"), names(args))
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>To calculate the length of the run, we find the length of the key,
but we have to be careful to evaluate the NROW within the environment
that the key will be in.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    calculate_run_length <- function(key_to_eval) {
      eval(bquote(NROW(.(key_to_eval))),
        envir = parent.frame(environment_that_contains_the_key(key_to_eval)))
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Finding the environment that contains the tree is tricky, because we have to
traverse environments through the parent frames outside of the batchman call and
into the containing environment where <code>batch</code> was originally called from.</p>

<p>We can use <code>parent.frame(n)</code> to search <code>n</code> frames up. We know that batchman occupies
two frames, so that means that the key will be in either the third or the fourth
frame from our current position, depending on whether there is an intervening
package call in the frame or not.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    environment_that_contains_the_key <- function(key_to_eval) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If the key is not a variable, we don&#39;t actually need to search a particular frame.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      if (!is(key_to_eval, "name")) return(3)
      frames_to_search = c(3, 4)
      for (frame in frames_to_search) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Use <code>exists</code> to see if the variable exists within that frame.
If we find it, return that frame.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if(exists(as.character(key_to_eval),</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Actually search one more frame up, because we&#39;re in a for loop, and that&#39;s
another frame.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          envir = parent.frame(frame + 1),
          inherits = FALSE
        )) { return(frame) }
      }
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>This function will return the next batch each time it is called.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    batch_calls <- function(run_length, where_the_keys_at, args, size) {
      keys <- args[where_the_keys_at]</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p><code>i</code> keeps track of where in the batch we are.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      i <- 1</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We want to subset the entire set of possible args, from positions y to z,
where y is our current position in the batch and z is the current position
plus the size of the batch (going from the start to the end of the batch).</p>

<p><code>all_args</code>, <code>start</code>, and <code>finish</code> will be dynamically rewritten to be the
correct values through the magic of R.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      selected_args <- quote(all_args[seq(start, finish)])
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Okay, this is the actual function that returns the next batch each time it is called.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      make_batch_call <- function() {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If we have exceeded our run length, we are done, so we return a special
done indicator that can be detected by batchman later to signal the end.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if (i > run_length) return(done)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If we&#39;re not done, we rewrite selected_args to have the correct values.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        for (j in where_the_keys_at) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Substtitue to the actual args for <code>all_args</code>.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          selected_args[[2]] <- args[[j]]</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Substitute our current position for <code>start</code>.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          selected_args[[3]][[2]] <- i</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Substitute the end index of this batch for <code>finish</code></p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          ending_index <- min(i + size - 1, run_length)
          selected_args[[3]][[3]] <- ending_index</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Write the subset back onto the arg list.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          args[[j]] <- selected_args
        }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Increment our position to the start of the next batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        i <<- i + size</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Return the metadata for batchman to look at, with the args, keys, and
number of batches.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        list("new_call" = args,
          "keys" = keys,
          "num_batches" = ceiling(run_length / size))
      }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Parallelize the batching across all the cores.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      function(ncores) {
        lapply(1:ncores, function(core_idx) {
          make_batch_call()
        })
      }
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p><code>process_batches</code> takes each batch one at a time and evaluates it.</p>

<p>It is initialized by a function called <code>next_batch</code> that, when it is called,
returns the next batch until we are out of batches.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    process_batches <- function(next_batch) {
      if (is.null(next_batch)) return(NULL)
      ncores <- if (isTRUE(parallel)) { ncores } else { 1 }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>batch_info fetches the metadata (processed args, keys to batch on, and
number of batches) for the batches.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      batch_info <- next_batch(ncores)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Get the args for each batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      new_call <- lapply(batch_info, `[[`, 'new_call')</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The <code>run_env</code> is an environment that contains the original function we want to
batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      run_env <- list2env(list(batch_fn = batch_fn))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We give the run_env access to the environment with the variables that we need to
calculate all the args.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      parent.env(run_env) <- parent.frame(environment_that_contains_the_key(
        batch_info[[1]]$keys[[1]]))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Batchman can track progress with a fancy progress bar.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      p <- if (verbose_set()) progress_bar(ceiling(batch_info[[1]]$num_batches/ncores))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Either <code>lapply</code> or <code>mclapply</code> depending on whether we are parallel.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      apply_method <- if (isTRUE(parallel)) { parallel::mclapply } else { lapply }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>As long as we don&#39;t encounter an end-of-batch done indicator, we will keep looping
through the batches and process them.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      while(!is.done(new_call[[1]])) {
        temp_batches <- apply_method(new_call, function(newcall, ...) {
          if (is.done(newcall)) return(structure(NULL, emptyrun = TRUE))</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If trycatch is enabled, we will attempt to retry multiple times.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          if (isTRUE(trycatch) && !isTRUE(parallel)) {
            iterated_try_catch(eval(newcall, envir = run_env),
              newcall, run_env, retry)
          } else {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Otherwise, just evaluate the call immediately.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">            eval(newcall, envir = run_env)
          }
        }, mc.cores = ncores, mc.allow.recursive = FALSE, mc.preschedule = TRUE)
        if (verbose_set()) { update_progress_bar(p) }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We might want to sleep between batches (for example, to not overload an API).
If the user has enabled it, we sleep here.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if (sleep > 0) { Sys.sleep(sleep) }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Parallel execution requires some special error handling.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        errors <- vapply(temp_batches, function(x) is(x, 'try-error'), logical(1))
        if (any(errors)) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>If a batch has failed, we warn or stop, as the user requested.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          if (isTRUE(stop)) {
            stop(attr(temp_batches[errors][[1]], 'condition'))
          } else {
            warning(as.character(attr(temp_batches[errors][[1]], 'condition')))
            temp_batches[errors] <- list(NULL)
          }
        }
        temp_batches  <- temp_batches[vapply(temp_batches, Negate(is.emptyrun), logical(1))]</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We then use the combination_strategy to combine all the batches.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        current_batch <- Reduce(combination_strategy, temp_batches)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We initialize batches to be a &ldquo;no batches&rdquo; (empty) indicator so that we can
combine the first element correctly.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        batches <- if (is.no_batches(batches)) current_batch
          else combination_strategy(batches, current_batch)
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We set the partial progress if the user has requested it.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if (isTRUE(trycatch)) partial_progress$set(batches)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>And we move onto the next batch.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        new_call <- lapply(next_batch(ncores), `[[`, 'new_call')
      }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Return the batches if there are any.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">      if (!is.no_batches(batches)) batches
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Verbose is true if it is enabled by the option OR
if it is not disabled by the option and is true in argument</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    verbose_set <- function() {
      isTRUE(getOption("batchman.verbose")) || (
        !identical(getOption("batchman.verbose"), FALSE) &&
        isTRUE(batchman.verbose)
      )
    }

    iterated_try_catch <- function(expr, new_call, run_env, current_try) {
      tryCatch(eval(new_call, envir = run_env),
        error = function(e) {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Warn or error as the user requests.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          raise_error_or_warning(e, current_try)</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Keep retrying until either we succeed or run out of retries.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">          if (current_try > 0) {
            if (isTRUE(verbose_set())) {
              cat("Retrying for the",
                as.ordinal(retry - current_try + 1),
                "time.\n")
            }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>Recursively retry</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">            iterated_try_catch(expr, new_call, run_env, current_try - 1)
          }
          else { NULL }
        }
      )
    }

    raise_error_or_warning <- function(e, retry) {
      if (isTRUE(stop) && retry == 0) {
        if (verbose_set()) cat("\nERROR... HALTING.\n")</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We can stop and give the user the partial progress.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if(exists("batches") && verbose_set()) {
          cat("Partial progress saved to batchman::progress()\n")
        }
        stop(e$message)
      } else {</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>The bad keys error is one we must stop on, regardless of what the user would like
because it doesn&#39;t work otherwise.  So we detect that and stop if needed.
Otherwise, we merely warn, abandon that batch, and go to the next one.</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">        if (grepl("Bad keys - no batched key", e$message)) stop(e$message)
        warning("Some of the data failed to process because: ", e$message)
      }
    }
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <p>We made it! Return the <code>batched_fn</code>, ready to process in batch!</p>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">    batched_fn
}</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>batchman-package.r</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' batchman.
#'
#' @name batchman
#' @import parallel
#' @docType package
NULL</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>combine.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Combine multiple objects into one object, regardless of class.
#' @param ... A list of batches to combine.
#' @return an object of the same class as original, but now including batch.
#' @export
combine <- function(...) {
  combine_by_list(list(...))
}

#' @inheritParams combine
#' @rdname combine
#' @export
combine_by_list <- function(combination_list) {
  if (!is(combination_list, "list")) {
    stop("Input must be a list. Call combine() instead.")
  }
  if (length(combination_list) == 1) return(combination_list[[1]])

  first <- combination_list[[1]]
  fn <- if (is.character(first) & length(first) == 1) paste0                   # String
  else if (class(first) %in% c("character", "numeric", "list", "logical", "integer", "NULL")) c   # Vector, List
  else if (is.data.frame(first)) {                # Data frame
    function(...) {
      do.call(plyr::rbind.fill, Filter(Negate(is.null), list(...)))
    }
  } else if (is.matrix(first)) merge              # Matrix
  else stop("Class for combine not recognized.")
  do.call(fn, combination_list)
}</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>progress-bar.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Progress bar with estimated time.
#'
#' This reference class represents a text progress bar displayed estimated
#' time remaining. When finished, it displays the total duration.
#'
#' @param n Total number of
#' @param min_time Progress bar will wait until at least \code{min_time}
#'   seconds have elapsed before displaying any results.
#' @return A ref class with methods \code{tick()}, \code{print()},
#'   \code{pause()}, and \code{stop()}.
#' @keywords internal
#' @author Hadley Wickham. <https://github.com/hadley/dplyr/blob/master/R/progress.R>
#' @export
#' @examples
#' p <- progress_estimated(3)
#' p$tick()
#' p$tick()
#' p$tick()
#'
#' p <- progress_estimated(3)
#' for (i in 1:3) p$pause(0.1)$tick()$print()
#'
#' p <- progress_estimated(3)
#' p$tick()$print()$
#'  pause(1)$stop()
#'
#' # If min_time is set, progress bar not shown until that many
#' # seconds have elapsed
#' p <- progress_estimated(3, min_time = 3)
#' for (i in 1:3) p$pause(0.1)$tick()$print()
#'
#' \dontrun{
#' p <- progress_estimated(10, min_time = 3)
#' for (i in 1:10) p$pause(0.5)$tick()$print()
#' }
progress_estimated <- function(n, min_time = 0) {
  Progress$new(n, min_time = min_time)
}

Progress <- R6::R6Class("Progress",
  public = list(
    n = NULL,
    i = 0,
    init_time = NULL,
    stopped = FALSE,
    stop_time = NULL,
    min_time = NULL,

    initialize = function(n, min_time = 0, ...) {
      self$n <- n
      self$min_time <- min_time
      self$begin()
    },

    begin = function() {
      "Initialise timer. Call this before beginning timing."
      self$i <- 0
      self$init_time <- now()
      self$stopped <- FALSE
      self
    },

    pause = function(x) {
      "Sleep for x seconds. Useful for testing."
      Sys.sleep(x)
      self
    },

    width = function() {
      getOption("width") - nchar("|100% ~ 99.9 h remaining") - 2
    },

    tick = function() {
      "Process one element"
      if (self$stopped) return(self)

      if (self$i == self$n) stop("No more ticks")
      self$i <- self$i + 1
      self
    },

    stop = function() {
      if (self$stopped) return(self)

      self$stopped <- TRUE
      self$stop_time <- now()
      self
    },

    print = function(...) {
      if(!interactive() || !is.null(getOption('knitr.in.progress'))) {
        return(invisible(self))
      }
      if (now() - self$init_time < self$min_time) {
        return(invisible(self))
      }

      if (self$stopped) {
        overall <- show_time(self$stop_time - self$init_time)
        if (self$i == self$n) {
          cat_line("Completed after ", overall)
          cat("\n")
        } else {
          cat_line("Killed after ", overall)
          cat("\n")
        }
        return(invisible(self))
      }

      avg <- (now() - self$init_time) / self$i
      time_left <- (self$n - self$i) * avg
      nbars <- trunc(self$i / self$n * self$width())

      cat_line(
        "|", str_rep("=", nbars), str_rep(" ", self$width() - nbars), "|",
        format(round(self$i / self$n * 100), width = 3), "% ",
        "~", show_time(time_left), " remaining"
      )

      invisible(self)
    }

  )
)

cat_line <- function(...) {
  msg <- paste(..., sep = "", collapse = "")
  gap <- max(c(0, getOption("width") - nchar(msg, "width")))
  cat("\r", msg, rep.int(" ", gap), sep = "")
  flush.console()
}

str_rep <- function(x, i) {
  paste(rep.int(x, i), collapse = "")
}

show_time <- function(x) {
  if (x < 60) {
    paste(round(x), "s")
  } else if (x < 60 * 60) {
    paste(round(x / 60), "m")
  } else {
    paste(round(x / (60 * 60)), "h")
  }
}

now <- function() proc.time()[[3]]

progress_bar <- function(num_batches) {
  if (suppressMessages(require(R6))) {
    progress_estimated(num_batches, min_time = 3)
  }
}

update_progress_bar <- function(bar) {
  if (!is.null(bar)) bar$tick()$print() else cat(".")
}</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>progress.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">#' Stores partial progress.
#' 
#' If a batch breaks, you don't want to lose all your progress done up until
#' that batch.  Batchman allows partial progress to be stored and retrieved.
#'
#' @export
progress <- function() batchman:::partial_progress$get()

partial_progress <- local({
  .cache <- list()
  structure(list(
    get = function() .cache,
    clear = function() .cache <<- list(),
    set = function(value) .cache <<- value
  ))
})
</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>testing-utils.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">rbomb <- local({
  .defused <- FALSE  # Whether or not it will explode when evaluated
  .stubborness <- 1  # How many defuses it takes to
  structure(list(
    class = "rbomb",
    is.defused = function() .defused,
    set_stubborness = function(val) .stubborness <<- val,
    defuse = function() {
      if (.stubborness == 1) {
        .defused <<- TRUE
      } else {
        .stubborness <<- .stubborness - 1
      }
      invisible()
    },
    reset = function() {
      .defused <<- FALSE
      .stubbornness <<- 1
      invisible()
    },
    detonate = function(val = 1) {
      if (!rbomb$is.defused()) {
        rbomb$defuse()
        stop("ESPLODZE!")
      } else val
    }
  ))
})

reverse <- function(x, y) c(y, x)

fncaller <- function(list_fn) list_fn[[1]]()

fn1 <- function() 1

get_expect_error_fn <- function(trycatch = TRUE, stop = FALSE, retry = 0, parallel = FALSE) {
  batchman:::partial_progress$clear()
  batch(
    fncaller,
    "list_fn",
    combination_strategy = function(x,y) unlist(c(x,y)),
    size = 1,
    batchman.verbose = FALSE,
    trycatch = trycatch,
    stop = stop,
    retry = retry,
    parallel = parallel
  )
}

error_fn <- function(x) { stop('ERROR') }</span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            <h1>utils.R</h1>

          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer"></span></code>
            </pre>
          </div>
        </div>
        <div class="section">
          <div class="markdown markdown-body">
            
          </div>

          <div class="code">
            <pre>
              <code class="R"><span class="spacer">batches <- structure(list(), class = "no_batches")
done <- list("new_call" = structure(list(), class = "batchman.is.done"))

#' A helper method to determine if batches doesn't contain batches.
#' @param batches The object to see if it contains batches.
is.no_batches <- function(batches) is(batches, "no_batches")

#' A helper method to determine if an empty batch was scheduled to run.
#' @param batches The object to see if it contains batches.
is.emptyrun <- function(x) identical(x, structure(NULL, emptyrun = TRUE))

#' A helper method to determine if batchman is done batching.
#' @param call The batchman call object.
is.done <- function(call) is(call, "batchman.is.done")

#' A helper method to determine if a function is already batched.
#' @param fn function. The function to test.
#' @export
is.batched_fn <- function(fn) isTRUE(attr(fn, "batched"))

#' A helper method to get the pre-batched function of a batched function.
#' @param fn function. The batched function to look for.
#' @export
get_before_fn <- function(fn) environment(fn)$batch_fn

#' @rdname get_before_fn
#' @export
unbatched <- get_before_fn

#' Print batched functions as they once were.
#' @param fn function. The function to print.
#' @export
print.batched_function <- function(fn) print(list(before_fn = get_before_fn(fn), after_fn = body(fn)))


#' Converts a number to an ordinal (e.g., first, second, etc.)
#' @param num numeric. The number to convert to ordinal.
#' @export
as.ordinal <- function(num) {
  ordinals <- list('first', 'second', 'third', 'fourth', 'fifth',
    'sixth', 'seventh', 'eighth', 'ninth', 'tenth', 'eleventh',
    'twelfth', 'thirteenth', 'fourteenth', 'fifteenth',
    'sixteenth', 'seventeenth', 'eighteenth', 'nineteenth',
    'twentieth')
  ext <- c("th", "st", "nd", "rd", rep("th", 6))
  ordinals[num][[1]] %||%
  paste0(num, ext[[(num %% 10) + 1]])
}</span></code>
            </pre>
          </div>
        </div>
      <div class="section">
      </div>

    </div>
  </body>
</html>
